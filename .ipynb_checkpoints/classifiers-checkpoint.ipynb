{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rcParams['text.color'], mpl.rcParams['axes.labelcolor'], mpl.rcParams['xtick.color'], mpl.rcParams['ytick.color'] = ['white']*4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveBayesClf:\n",
    "    def __init__(self, algo='gaussian', alpha=1.0):\n",
    "        '''\n",
    "        algo:str - 'gaussian': For normal distribution, Used for classification.\n",
    "                   'bernoulli': used when feature vectors are binary\n",
    "                   'multinomial': For multinomially distributed data, if alpha=1, Laplace smoothing\n",
    "                                                                      elif alpha < 1, Lidstone smoothing\n",
    "                                                                      else alpha >= 0, prevents zero probabilities\n",
    "                   'complement': Adaptation of the standard Multinomial Naive Bayes (MNB) algorithm \n",
    "                       that is particularly suited for imbalanced data sets wherein the algorithm \n",
    "                       uses statistics from the complement of each class to compute the modelâ€™s weight.\n",
    "        alpha:float - \n",
    "        '''\n",
    "        self.alpha = alpha\n",
    "        self.algo = algo\n",
    "        \n",
    "    def train(self, X, y, use_pandas=False):\n",
    "        '''\n",
    "        X - (n_datapoints, n_features)\n",
    "        y - (n_datapoints, 1)\n",
    "        '''\n",
    "        if X.ndim == 1:\n",
    "            X = X.reshape(-1, 1)\n",
    "        n_datapoints, n_features = X.shape\n",
    "        assert len(y) == n_datapoints\n",
    "        y = y.reshape(-1, 1)\n",
    "        # https://towardsdatascience.com/how-to-impliment-a-gaussian-naive-bayes-classifier-in-python-from-scratch-11e0b80faf5a\n",
    "        # Frequency Table / Prior probabilities\n",
    "        classes = np.unique(y)\n",
    "        if use_pandas:\n",
    "            import pandas as pd\n",
    "            f_table = pd.crosstab(X, [y]).values\n",
    "        else:\n",
    "            unique_X = np.unique(X)\n",
    "            f_table = np.zeros((len(unique_X), len(classes)))\n",
    "            for i in range(len(unique_X)):\n",
    "                l, c = np.unique(y[X == unique_X[i]], return_counts=True)\n",
    "                f_table[i, l] = c\n",
    "        # Likelihood table\n",
    "#         l_table = np.hstack([f_table, f_table.sum(axis=1, keepdims=True) / n_datapoints])\n",
    "#         l_table = np.vstack((l_table, l_table.sum(axis=0, keepdims=True) / n_datapoints))\n",
    "        self.priors = f_table.sum(axis=0, keepdims=True) / n_datapoints\n",
    "        self.mu = f_table.mean(axis=0, keepdims=True)\n",
    "        self.sigma = f_table.std(axis=0, keepdims=True)\n",
    "    \n",
    "    def predict(self, X, return_probs=False):\n",
    "        '''\n",
    "        https://wikimedia.org/api/rest_v1/media/math/render/svg/1eaed580cf7c29f044a9e517f1cd4a7dd69c4b1f\n",
    "        '''\n",
    "        # Creates a 3 dimensional array with X transposed and repeated on the 3rd dimension (n_unique_classes) times\n",
    "        if self.algo == 'gaussian':\n",
    "            # cond_prob - ((X.shape[1], X.shape[0], repeats))\n",
    "            cond_prob = np.exp(-((np.tile(X.T, (1, 1, self.mu.shape[0])) - self.mu.T)**2 / 2 / self.sigma.T**2)) / (2*np.pi)**0.5 / self.sigma.T\n",
    "        elif self.algo == '':\n",
    "            f_table = f_table\n",
    "        probs = self.priors.T * cond_prob.prod(axis=0)\n",
    "        yp = probs.argmax(axis=0)\n",
    "        if return_probs:\n",
    "            return yp, probs\n",
    "        return yp\n",
    "        \n",
    "        \n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1, 1, 0, 1, 0, 0, 0, 1, 1]), array([1, 1, 0, 1, 1, 1, 0, 0, 1]))"
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_sk = GaussianNB()\n",
    "clf_sk.fit(X, y)\n",
    "\n",
    "y, clf_sk.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1, 1, 0, 1, 0, 0, 0, 1, 1]),\n",
       " array([0, 1, 1, 1, 1, 0, 1, 1, 0], dtype=int64))"
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = NaiveBayesClf()\n",
    "clf.train(X, y)\n",
    "yp, p = clf.predict(X, return_probs=True)\n",
    "y, yp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian naive Bayes\n",
    "<img src=\"https://wikimedia.org/api/rest_v1/media/math/render/svg/685339e22f57b18d804f2e0a9c507421da59e2ab\">\n",
    "\n",
    "## Multinomial naive Bayes\n",
    "<img src=\"\">\n",
    "\n",
    "## Bernoulli naive Bayes\n",
    "<img src=\"\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GaussianNB:\n",
    "    def __init__(self, ):\n",
    "        super().__init__(algo='gaussian')\n",
    "class BernoulliNB:\n",
    "    def __init__(self, ):\n",
    "        super().__init__(algo='bernoulli')\n",
    "class MultinomialNB:\n",
    "    def __init__(self, ):\n",
    "        super().__init__(algo='multinomial')\n",
    "class ComplementNB:\n",
    "    def __init__(self, ):\n",
    "        super().__init__(algo='complement')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing with sklearn module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper function to compare and plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-315-12247b2c831b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnaive_bayes\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mGaussianNB\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mclf_sk\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGaussianNB\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mclf_sk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0myp_sk\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclf_sk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, plot_confusion_matrix\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "clf_sk = GaussianNB()\n",
    "clf_sk.fit(X_train, y_train)\n",
    "\n",
    "yp_sk = clf_sk.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "def plot_pipe(X, y, models, feature=None, fit_intercept=True, normalize=False, norm_method=\"fro\", penalty=0.1, test_size=0.3):\n",
    "    plt.figure(figsize=(10,15))\n",
    "    if X.ndim == 2:\n",
    "        if X.shape[1] > 1:\n",
    "            if feature is None:\n",
    "                print(\"Supported only for 1 feature, ignoring other features\")\n",
    "                X = X[:, 0].reshape(-1, 1)\n",
    "            else:\n",
    "                X = X[:, feature].reshape(-1, 1)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size)\n",
    "    plt.scatter(X_train, y_train, color='black')\n",
    "    plt.scatter(X_test, y_test, color='blue')\n",
    "    legend = []\n",
    "    for k in models:\n",
    "        if 'sk' in k:\n",
    "            r = models[k](fit_intercept=fit_intercept, normalize=normalize)\n",
    "            r.fit(X_train, y_train.reshape(-1, 1))\n",
    "            cf = [r.intercept_, r.coef_]\n",
    "        else:\n",
    "            if normalize:\n",
    "                X_train = Normalizer(method=norm_method).normalize(X_train)\n",
    "                X_test = Normalizer(method=norm_method).normalize(X_test)\n",
    "            r = models[k](fit_intercept=fit_intercept, penalty=penalty)\n",
    "            r.train(X_train, y_train)\n",
    "            cf = r.W\n",
    "\n",
    "        y_pred = r.predict(X)\n",
    "        print(\"-\"*20, k, \"-\"*20)\n",
    "        print(\"Coefficients - \", cf)\n",
    "        print(\"sklearn R2 scores ---------\")\n",
    "        print(\"Test R2 score = \", r2_score(y_test, r.predict(X_test)))\n",
    "        print(\"Whole dataset R2 score = \", r2_score(y, y_pred))\n",
    "        print(\"My R2 scores ---------\")\n",
    "        print(\"Test R2 score = \", LinearRegression().r2_score(y_test, r.predict(X_test)))\n",
    "        print(\"Whole dataset R2 score = \", LinearRegression().r2_score(y, y_pred))\n",
    "        \n",
    "        plt.plot([X.max(), X.min()], [y_pred.max(), y_pred.min()])\n",
    "        \n",
    "        legend.append(k)\n",
    "    legend.extend([\"Train\", \"Test\"])\n",
    "    plt.legend(legend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X = np.array([1, 2, 5, 2, 2, 1, 5, 5, 1]).reshape(-1, 1)\n",
    "y = np.array([1,1,0,1,0,0,0,1,1])\n",
    "# models = {\n",
    "#     'skLR': linear_model.LinearRegression,\n",
    "#     'myLR': LinearRegression,\n",
    "#     'skLasso': linear_model.Lasso,\n",
    "#     'myLasso': Lasso,\n",
    "#     'skRidge': linear_model.Ridge,\n",
    "#     'myRidge': Ridge\n",
    "# }\n",
    "# plot_pipe(X, y, models, feature=2, fit_intercept=True, penalty=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets, linear_model\n",
    "X, y = datasets.load_diabetes(return_X_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
