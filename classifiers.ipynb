{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rcParams['text.color'], mpl.rcParams['axes.labelcolor'], mpl.rcParams['xtick.color'], mpl.rcParams['ytick.color'] = ['white']*4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveBayesClf:\n",
    "    def __init__(self, algo='gaussian', alpha=None):\n",
    "        '''\n",
    "        algo:str - 'gaussian': For normal distribution, Used for classification.\n",
    "                   'multinomial': For multinomially distributed data\n",
    "                   'bernoulli': used when feature vectors are binary\n",
    "                   'complement': Adaptation of the standard Multinomial Naive Bayes (MNB) algorithm \n",
    "                       that is particularly suited for imbalanced data sets wherein the algorithm \n",
    "                       uses statistics from the complement of each class to compute the modelâ€™s weight.\n",
    "        alpha:float - for 'gaussian' algorithm, alpha is the \n",
    "                        for 'multinomial' algorithm, if alpha=1, Laplace smoothing\n",
    "                                        elif alpha < 1, Lidstone smoothing\n",
    "                                        else alpha >= 0, prevents zero probabilities\n",
    "        '''\n",
    "        if algo == 'gaussian':\n",
    "            self.algo = algo\n",
    "            if alpha is None:\n",
    "                alpha = 1e-9\n",
    "            self.alpha = alpha\n",
    "        elif algo == 'multinomial':\n",
    "            self.algo = algo\n",
    "            if alpha is None:\n",
    "                alpha = 1.0\n",
    "            self.alpha = alpha\n",
    "\n",
    "    def train(self, X, y):\n",
    "        '''\n",
    "        X - (n_datapoints, n_features)\n",
    "        y - (n_datapoints, 1)\n",
    "        '''\n",
    "        if X.ndim == 1:\n",
    "            X = X.reshape(-1, 1)\n",
    "        n_datapoints, n_features = X.shape\n",
    "        assert len(y) == n_datapoints\n",
    "        y = y.reshape(-1)\n",
    "        \n",
    "        classes = np.unique(y)\n",
    "        n_classes = len(classes)\n",
    "        priors = np.zeros((n_classes, 1))\n",
    "        mu = np.zeros((n_classes, n_features))\n",
    "        sigma2 = np.zeros((n_classes, n_features))\n",
    "        # ith class features will be stored in ith index\n",
    "        features_by_class = []\n",
    "        for i in range(n_classes):\n",
    "            features_by_class.append(X[y==classes[i], :])\n",
    "            priors[i] = len(features_by_class[-1]) / n_datapoints\n",
    "            mu[i] = features_by_class[-1].mean(axis=0)\n",
    "            sigma2[i] = features_by_class[-1].var(axis=0)\n",
    "        self.n_classes = n_classes\n",
    "        self.priors = priors\n",
    "        self.mu = mu\n",
    "        self.sigma2 = sigma2 + self.alpha * np.var(X, axis=0).max()    # To avoid numerical error (from sklearn source)\n",
    "    \n",
    "    def predict(self, X, return_probs=False):\n",
    "        if X.ndim == 1:\n",
    "            X = X.reshape(-1, 1)\n",
    "        if self.algo == 'gaussian':\n",
    "            cond_prob = np.zeros((self.n_classes, X.shape[0]))\n",
    "            for i in range(self.n_classes):\n",
    "                cond_prob[i, :] = (np.exp(-((X-self.mu[i])**2 / (2 * self.sigma2[i]))) / np.sqrt(2*np.pi*self.sigma2[i])).prod(axis=1)\n",
    "            probs = self.priors * cond_prob\n",
    "            yp = probs.argmax(axis=0)\n",
    "        elif self.algo == 'multinomial':\n",
    "            pass\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "        if return_probs:\n",
    "            return yp, probs\n",
    "        return yp\n",
    "    \n",
    "    @staticmethod\n",
    "    def score(y, y_pred):\n",
    "        return 100 * (y==y_pred).sum() / len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GaussianNB:\n",
    "    def __init__(self, ):\n",
    "        super().__init__(algo='gaussian')\n",
    "class BernoulliNB:\n",
    "    def __init__(self, ):\n",
    "        super().__init__(algo='bernoulli')\n",
    "class MultinomialNB:\n",
    "    def __init__(self, ):\n",
    "        super().__init__(algo='multinomial')\n",
    "class ComplementNB:\n",
    "    def __init__(self, ):\n",
    "        super().__init__(algo='complement')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing with sklearn module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper function to compare and plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, plot_confusion_matrix\n",
    "def pipe(X, y, models, feature=None, fit_prior=True, normalize=False, norm_method=\"fro\", alpha=1, test_size=0.3):\n",
    "#     plt.figure(figsize=(10,15))\n",
    "#     plot_X = X\n",
    "#     if X.ndim == 2:\n",
    "#         if X.shape[1] > 1:\n",
    "#             if feature is None:\n",
    "#                 print(\"Supported only for 1 feature, ignoring other features for plotting\")\n",
    "#                 plot_X = X[:, 0].reshape(-1, 1)\n",
    "#             else:\n",
    "#                 plot_X = X[:, feature].reshape(-1, 1)\n",
    "#     plt.scatter(plot_X, y, color='black')\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size)\n",
    "    for k in models:\n",
    "        print(k)\n",
    "        if 'sk' in k:\n",
    "            models[k].fit(X_train, y_train)\n",
    "        else:\n",
    "            if normalize:\n",
    "                X_train = Normalizer(method=norm_method).normalize(X_train)\n",
    "                X_test = Normalizer(method=norm_method).normalize(X_test)\n",
    "            models[k].train(X_train, y_train)\n",
    "\n",
    "        y_pred = models[k].predict(X)\n",
    "        print(\"-\"*20, k, \"-\"*20)\n",
    "        print(\"sklearn Accuracy scores ---------\")\n",
    "        print(\"Test Accuracy score = \", accuracy_score(y_test, models[k].predict(X_test)))\n",
    "        print(\"Whole dataset Accuracy score = \", accuracy_score(y, y_pred))\n",
    "        print(\"My Accuracy scores ---------\")\n",
    "        print(\"Test Accuracy score = \", NaiveBayesClf().score(y_test, models[k].predict(X_test)))\n",
    "        print(\"Whole dataset Accuracy score = \", NaiveBayesClf().score(y, y_pred))\n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([1, 2, 5, 3, 2, 2, 1, 5, 5, 1, 3]).reshape(-1, 1)\n",
    "y = np.array([1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets, linear_model\n",
    "X, y = datasets.load_diabetes(return_X_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = datasets.load_iris(return_X_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x1aacefa8888>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD4CAYAAADiry33AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAZRElEQVR4nO3dfZCcxWHn8e/cIuE1kS2wggIrgTBWlOADo3hLglPKFiFCwnaQzqbKqOCMczZKXLHzwpWu4KCMTKBIoisuyR0xEbaCHbDwhWCdcomR5XM4uwjSaYUIMtgKIGMkLSfZCAHGewitn/ujn109OzuzT+/uo9lR7/dTNaV5up+Xnp6Z3zzT86y6lmUZkqR0/auJboAk6fgy6CUpcQa9JCXOoJekxBn0kpS4kya6AY3MmDEjmzNnzkQ3Q5JOGDt27PhxlmU/36iuLYN+zpw59PT0THQzJOmEUavVftiszqEbSUqcQS9JiTPoJSlxBr0kJc6gl6TEGfSSlLiYoJ8N/CPwPeAp4PcarFMD/hx4FngS+JVC3bXAM/nt2vE0VpI0ejHX0R8F/gPwODAN2AFsAZ4urHM5MDe/LQQ+n/97GnAL0A1k+babgJeraX6aNu7cz9rNu+k93MeZ0ztZvXQeK+Z3TXSzjouyxxrTF1ff8xiPPndocHnRuadx/3UXj2ofN2/cxYZte+nPMjpqNVYunM1tK86vrB7gglse5tU3+geX33ZyB09+btng8sLbt3DgtSODyzOnTWXbTUuG7GPJnY/wzMHXB5fnnn4KW65f3LhzG4g5RtljKevvGK14Xqt4H8XsY7zPSSve7zFn9C8SQh7gNcKZfX0rlgNfJoT5VmA6cAawlPChcIgQ7luAZaipjTv3c+NDu9h/uI8M2H+4jxsf2sXGnfsnummVK3usMX1RHwYAjz53iKvveSx6Hzdv3MV9W1+gP5+boT/LuG/rC9y8cVcl9TA85AFefaOfC255GBgewAAHXjvCwtu3DC7XBwrAMwdfZ8mdj4zc0bmYY5Q9lrL+jtGK57WK91HMPsb7nLTq/T7aMfo5wHxgW115F7C3sLwvL2tWribWbt5N35tDA6HvzX7Wbt49QS06fsoea0xf1IdBfXnMPjZs20sjA+XjrQeGhXx9eX0ADyiW1wdKWflI+2pWXvZYyvo7Riue1yreRzH7GO9z0qr3+2j+C4SfA/4W+H3g1bq6WoP1sxHKG1mV3ya13sN9oyo/kZU91ir6ImYf/U1mWSue1Y6n/kTSisfSiue1Va+d8WrV+z32jH4KIeTvBx5qUL+P8KPtgFlA7wjljawjjOV3R7YpSWdO7xxV+Yms7LFW0Rcx++ioNTofOVY+3voTSSseSyue11a9dsarVe/3mKCvAV8kjM3f2WSdTcDH8nUvAl4hjO1vBi4DTs1vl+VlamL10nl0TukYUtY5pYPVS+dNUIuOn7LHGtMXi849reG+B8pj9rFy4WwaGSgfbz2EH14bGSifOW1qw/pi+dzTT2m4TrPykfbVrLzssZT1d4xWPK9VvI9i9jHe56RV7/eONWvWlK3zq8CfAqcAvwX8NvACcCnh7LuHcFnlxYRLLC8nDMH0An2EH3D/Oi+7DSj91WbdunVrVq2anKM4v3TG25h1aie79r/CT/7fUbqmd/LZ3zgvyatuyh5rTF985L2z2f6Dl9j78rGvusWrM2L28Wu/NJMf/+QNntr/Khnh7PXqi84avNJkvPUAn7rkXaz/zh7e6D82BFK86ua6953Lhm0/5PUjx8Zr66+I+djFc/j7J3s59Pqbg2WjucIj5hhlj6Wsv2O04nmt4n0Us4/xPidVvt8/97nPvbhmzZp1jepqWRuOI3Z3d2f+N8WSFK9Wq+3Isqzh0Ld/GStJiTPoJSlxBr0kJc6gl6TEGfSSlDiDXpISZ9BLUuIMeklKnEEvSYkz6CUpcQa9JCXOoJekxBn0kpQ4g16SEmfQS1LiDHpJSlxM0K8HDgLfbVK/Gngiv30X6AcG5gF7HtiV1zmTiCRNgJigvxdYNkL9WuDC/HYj8L+BQ4X6S/K6ST3ptyRNlJig/zZDg3skK4ENY2+OJKlqVY7Rv5Vw5v+3hbIM+AawgzA5+EhWEYZ3HOKRpAqdVOG+fgN4lKFn/4uAXuB0YAvwfcI3hEbW5TcIHxCSpApUeUZ/FcOHbXrzfw8CXwMWVHg8SVKEqoL+7cD7gf9RKDsFmFa4fxnNr9yRJB0nMUM3G4DFwAxgH3ALMCWvuzv/998SxuJfL2w3k3AWP3CcrwAPj6+5kqTRign6lRHr3JvfivYA7xlleyRJFfMvYyUpcQa9JCXOoJekxBn0kpQ4g16SEmfQS1LiDHpJSpxBL0mJM+glKXEGvSQlzqCXpMQZ9JKUOINekhJn0EtS4gx6SUpcTNCvJ0wF2Gx2qMXAK8AT+e2zhbplwG7gWeCGMbdSkjRmMUF/LyGwR/Id4ML8dmte1gHcBVwOnEeYwOS8MbVSkjRmMUH/beDQGPa9gHAmvwc4AjwALB/DfiRJ41DVGP3FwD8DXwfenZd1AXsL6+zLy5pZBfTkN0lSRWLmjC3zOHA28BPgA8BGYC5Qa7BuNsJ+1uW3svUkSaNQxRn9q4SQB/gHYAowg3AGP7uw3iygt4LjSZJGoYqg/wWOnb0vyPf5ErCdcGZ/DjAVuArYVMHxJEmjEDN0s4FwCeXAWfothLN2gLuBK4FPAUeBPkKgZ/nyp4HNhCtw1gNPVdd0SVKMWpa133B4d3d31tPjb7KSFKtWq+3Isqy7UZ1/GStJiTPoJSlxBr0kJc6gl6TEGfSSlDiDXpISZ9BLUuIMeklKnEEvSYkz6CUpcQa9JCXOoJekxBn0kpQ4g16SEmfQS1LiDHpJSlxM0K8HDgLfbVJ/NfBkfvsn4D2FuueBXcATgDOJSNIEiAn6e4FlI9T/AHg/cAHwh8C6uvpLgAuBhjOfSJKOr5g5Y78NzBmh/p8K97cCs8bTIElStaoeo/8E8PXCcgZ8A9gBrCrZdhVheMchHkmqUMwZfaxLCEH/q4WyRUAvcDqwBfg+4RtCI+s4NuzTfjOWS9IJqqoz+guALwDLgZcK5b35vweBrwELKjqeJClSFUF/FvAQ8O+AfymUnwJMK9y/jOZX7kiSjpOYoZsNwGJgBrAPuAWYktfdDXwWeAfwF3nZUcIVNjMJZ/EDx/kK8HAVjZYkxYsJ+pUl9Z/Mb/X2MPSaeknSBPAvYyUpcQa9JCXOoJekxBn0kpQ4g16SEmfQS1LiDHpJSpxBL0mJM+glKXEGvSQlzqCXpMQZ9JKUOINekhJn0EtS4gx6SUpc7Jyx64EPEaYE/NcN6mvAnwEfAH4KfBx4PK+7Frg5v38b8KUxtnXS2LhzP2s376b3cB9nTu9k9dJ5rJjfNVh/88ZdbNi2l/4so6NWY+XC2dy24vxR7aOsvop2Lrx9CwdeOzK4PHPaVLbdtGTIPsrWidnH1fc8xqPPHRpcXnTuadx/3cWDyzH9teTOR3jm4OuDy3NPP4Ut1y+Oro85RhXtHO9ro6wNMceIee1U8fpSdWpZFjUP9/uAnwBfpnHQfwD4TP7vQkLoLwROA3oIM05lwA7gvcDLIx2su7s76+npiXsEidm4cz83PrSLvjf7B8s6p3Rwx4fPZ8X8Lm7euIv7tr4wbLtrLjpr8A1dto+y+iraWR/QA4pBXbZOzD7qg2vAQIDF9Fd9iA8YCPOy+phjVNHO8b42ytoQc4yY104Vry+NXq1W25FlWXejutihm28Dw18hxywnfAhkwFZgOnAGsBTYkm/7cn5/WeQxJ6W1m3cPeYMA9L3Zz9rNuwHYsG1vw+2K5WX7KKuvop2NArq+vGydmH00Cq5ieUx/NQrxYnlZfcwxqmjneF8bZW2IOUbMa6eK15eqFTt0U6YLKL7K9uVlzcobWZXfJrXew30jlvc3+QZWLC/bR1l9Fe1sFzH91Q7HqOJ5raIdVbx2TpTXxmRS1Y+xtQZl2QjljawjDPE0/OoxWZw5vXPE8o5aoy4dWl62j7L6KtrZLmL6qx2OUcXzWkU7qnjtnCivjcmkqqDfB8wuLM8CekcoVxOrl86jc0rHkLLOKR2sXjoPgJULZzfabEh52T7K6qto58xpUxtuVywvWydmH4vOPa3hOgPlMf019/RTGq4zUF5WH3OMKto53tdGWRtijhHz2qni9aVqVRX0m4CPEc7gLwJeAV4ENgOXAafmt8vyMjWxYn4Xd3z4fLqmd1IDuqZ3DvkR67YV53PNRWcNnqV11GpDfrCL2UdZfRXt3HbTkmFBXX/FTNk6Mfu4/7qLhwVY8cfFmP7acv3iYWFevKqmrD7mGFW0c7yvjbI2xBwj5rVTxetL1Yq96mYDsBiYARwAbgGm5HV3EwL+vxF+aP0p8JuEq20A/j3wn/L7twN/VXawyXzVjSSNxUhX3cT+GLuypD4DfqdJ3fr8JkmaAP5lrCQlzqCXpMQZ9JKUOINekhJn0EtS4gx6SUqcQS9JiTPoJSlxBr0kJc6gl6TEGfSSlDiDXpISZ9BLUuIMeklKnEEvSYmLDfplwG7gWeCGBvX/BXgiv/0LcLhQ11+o2zTmlkqSxiRm4pEO4C5gCWEO2O2EwH66sM4fFO5/BphfWO4DLhxfMyVJYxVzRr+AcCa/BzgCPAAsH2H9lYSpByVJbSAm6LuAvYXlfXlZI2cD5wDfKpS9hTB/7FZgxQjHWZWv52SxklShmKGbWoOyZjOKXwU8SBiXH3AW0Au8k/ABsAt4rsG26/LbSPuXJI1SzBn9PmB2YXkWIbgbuYrhwzYD6+4BHmHo+L0k6TiLCfrtwFzCkMxUQpg3unpmHnAq8Fih7FTg5Pz+DGARQ3/ElSQdZzFDN0eBTwObCVfgrAeeAm4ljKcPhP5Kwg+1xWGXXwb+EvgZ4UPljzDoJamlalnWfsPh3d3dWU+Pv8lKUqxarbYjy7LuRnX+ZawkJc6gl6TEGfSSlDiDXpISZ9BLUuIMeklKnEEvSYkz6CUpcQa9JCXOoJekxBn0kpQ4g16SEmfQS1LiDHpJSpxBL0mJM+glKXGxQb8M2A08C9zQoP7jwI+AJ/LbJwt11wLP5Ldrx9pQSdLYxEwl2AHcBSwhTBS+nTB9YP2UgF8lTDlYdBpwC9BNmGJwR77ty2NvsiRpNGLO6BcQzuT3AEcI88Iuj9z/UmALcIgQ7lsI3w4kSS0SE/RdwN7C8r68rN5HgCeBB4HZo9wWYBVhsnEni5WkCsUEfa1BWf2M4n8HzAEuAL4JfGkU2w5YRxjiaTi5rSRpbGKCfh/HztABZgG9deu8BLyR378HeO8otpUkHUcxQb8dmAucA0wFriL8oFp0RuH+FcD38vubgcuAU/PbZXmZJKlFYq66OUq4mmYz4Qqc9cBTwK2E8fRNwO8SAv4o4YfXj+fbHgL+kPBhQb7NoWqaLkmKUcuyZkPmE6e7uzvr6fE3WUmKVavVdmRZ1vA3Tv8yVpISZ9BLUuIMeklKnEEvSYkz6CUpcQa9JCXOoJekxBn0kpQ4g16SEmfQS1LiDHpJSpxBL0mJM+glKXEGvSQlzqCXpMTFBv0yYDfwLHBDg/rrgacJk4P/L+DsQl0/8ER+q5+ZSpJ0nMXMMNUB3AUsIcwBu50Q2E8X1tlJmNT7p8CngD8BPprX9QEXVtReSdIoxZzRLyCcye8BjgAPAMvr1vlHQsgDbCVMAi5JagMxQd8F7C0s78vLmvkE8PXC8lsIc8tuBVaMsN2qfD3nEJSkCsUM3dQalDWbaPYawhDO+wtlZwG9wDuBbwG7gOcabLsuv420f0nSKMWc0e8DZheWZxGCu96vAzcBVwBvFMoH1t0DPALMH3UrJUljFhP024G5wDnAVOAqhl89Mx/4S0LIHyyUnwqcnN+fASxi6I+4kqTjLGbo5ijwaWAz4Qqc9cBTwK2E8fRNwFrg54C/ybd5gRD6v0z4APgZ4UPljzDoJamlalnWfsPh3d3dWU+Pv8lKUqxarbYjy7LuRnX+ZawkJc6gl6TEGfSSlDiDXpISZ9BLUuIMeklKnEEvSYkz6CUpcQa9JCXOoJekxBn0kpQ4g16SEmfQS1LiDHpJSpxBL0mJiw36ZcBu4Fnghgb1JwNfzeu3AXMKdTfm5buBpWNtqCRpbGJmmOoA7gKWEOaP3U6YVao4U9QngJeBdxGmGvxj4KPAefnyu4EzgW8Cvwj0V9P8oTbu3M/azbvpPdzHmdM7Wb10Hivmdw3WX33PYzz63KHB5UXnnsb9110cvT3Akjsf4ZmDrw8uzz39FLZcv3hw+eaNu9iwbS/9WUZHrcbKhbO5bcX5Q/ax8PYtHHjtyODyzGlT2XbTkuhjvOvGv+doYb6Yk2rw7B0fHHKMsnXK+iKmP8oeR0xflInZR8zzJk1mMWf0Cwhn5HuAI8ADwPK6dZYDX8rvPwhcCtTy8gcIk4X/IN/PgnG3uoGNO/dz40O72H+4jwzYf7iPGx/axcad+4HhwQbw6HOHuPqex6K2h+EBDPDMwddZcucjQAil+7a+QH8+a1d/lnHf1he4eeOuwfXrwxHgwGtHWHj7lqhj1Ac4wNEslA8oW6esL2L6o+xxxPRFmZh9xDxv0mQXE/RdwN7C8r68rNk6R4FXgHdEbluJtZt30/fm0C8KfW/2s3bzboBhwTZgoLxse2BYANeXb9i2t2F9sbw+HOvLy45RH+ADiuVl65T1BZT3R9njiOmLMjH7iHnepMkuZuim1qCsPkqarROz7YBV+W1Meg/3jaq86u2BwTPP2PJ2Nt7+qKIvYvZRxfMmpS7mjH4fMLuwPAvoHWGdk4C3A4citx2wDujOb6N25vTOUZVXvT1AR63R51rz8nY23v6ooi9i9lHF8yalLibotwNzgXOAqYQfVzfVrbMJuDa/fyXwLcKZ+6Z8/ZPz7ecC/2fcrW5g9dJ5dE7pGFLWOaWD1UvnAeHHxkYGysu2h/CjaCMD5SsXzm5YXyyfOW1qw3UGysuOcVKTnCyWl61T1hdQ3h9ljyOmL8rE7CPmeZMmu5igPwp8GtgMfA/478BTwK3AFfk6XySMyT8LXM+xSzCfytd/GngY+B2O0xU3K+Z3cceHz6dreic1oGt6J3d8+PzBqy/uv+7iYQFXvNKkbHuALdcvHhbExStibltxPtdcdNbgGWdHrcY1F5015CqRbTctGRaSxatVyo7x7B0fHBbk9VfUlK1T1hcx/VH2OGL6okzMPmKeN2myq2VtOH7c3d2d9fT0THQzJOmEUavVdmRZ1nDo27+MlaTEGfSSlDiDXpISZ9BLUuIMeklKnEEvSYlry8sra7Xaj4AfTtTxZ86cOePAgQM/nqjjx7Kd1TtR2mo7q5VIO8/OsuznG1W0ZdC3gR7G+F8xtJjtrN6J0lbbWa2k2+nQjSQlzqCXpMR1rFmzZqLb0K52THQDItnO6p0obbWd1Uq2nY7RS1LiHLqRpMQZ9JKUOIMeOoCdwP9sUPdx4EfAE/ntk61r1hDPA7vyNjT6/5trwJ8T5gN4EviVlrVsqOcZuZ2LCfMJD/TnZ1vVsDrTCZPYf58wx8LFdfXt0p9l7VxMe/TnvEIbngBeBX6/bp126NOYdi6mPfr0DwjzeXwX2AC8pa7+ZOCrhP7cBswZaWcxc8am7vcIb6K3Nan/KmHilYl2CdDsDyUuJ8zeNRdYCHw+/3cijNROgO8AH2pRW5r5M8JEOFcSZk17a119u/RnWTuhPfpzN3Bhfr8D2A98rW6ddujTmHbCxPdpF/C7wHlAH2HypquAewvrfAJ4GXhXXvfHwEeb7XCyn9HPAj4IfGGiGzJOy4EvE6Zv3Eo4EzxjQlvUvt4GvI8wKxrAEeBw3Trt0J8x7WxHlwLPMfwv29uhT4uatbNdnAR05v++leFzbS8HvpTff5DweJpOyDzZg/5Pgf8I/GyEdT5C+Kr5IEMnOm+lDPgG4bKqVQ3qu4C9heV9eVmrlbUTwvDDPwNfB97donYVvZMwHPdXhCG7LwD1E/W2Q3/GtBMmvj/rXUUYaqjXDn1a1KydMPF9uh/4z8ALwIuEoaRv1K1T7M+j+TrvaLbDyRz0HwIOMvI1qX9HGPu6APgmxz5BW20RYUzzcsK8u++rq2/0ST4R182WtfNx4GzgPcB/BTa2tHXBSYQ2fh6YD7zOsTmOB7RDf8a0sx36s2gqYR7pv2lQ1w59OmCkdrZDn55KOGM/BziT8AF/Td06o+rPyRz0iwhP9vPAA8CvAffVrfMS8EZ+/x7gva1qXJ2Br20HCWOKC+rq9zH028Yshn/Va4Wydr4K/CS//w/AFGBGa5o2aF9+25YvP8jwHwbboT9j2tkO/Vl0OSEoDzSoa4c+HTBSO9uhT38d+AHhG92bwEPAv6lbp9ifJwFvBw412+FkDvobCS+2OYSvcd9i+KdmcQzxCsKPtq12CjCtcP8ywi/xRZuAjxE+5S8ifI17sVUNzMW08xc4diaygPD6e6klrTvm/xK+8s7Lly8Fnq5bpx36M6ad7dCfRStpPhzSDn06YKR2tkOfvkDoo7fmbbmU4dmzCbg2v38lIb+antF71c1wtxIuDdxE+OX7CsIY2CHC5ZatNpNjVwacBHyFcCXGb+dldxPOPD5AuNTqp8BvtriNENfOK4FPEfqzj/ABOxFf3z8D3E/4Cr+H0F/t1p9Q3s526U8IobQE+K1CWTv2aVk726FPtxG+wT2et2MnsI6h2fRF4K8J/Xkob2dT/hcIkpS4yTx0I0mTgkEvSYkz6CUpcQa9JCXOoJekxBn0kpQ4g16SEvf/AQzBhL/7woGiAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "dark"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(X[:, 0], y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.1, 7.9)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.min(), X.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skGNB\n",
      "-------------------- skGNB --------------------\n",
      "sklearn Accuracy scores ---------\n",
      "Test Accuracy score =  0.9777777777777777\n",
      "Whole dataset Accuracy score =  0.96\n",
      "My Accuracy scores ---------\n",
      "Test Accuracy score =  97.77777777777777\n",
      "Whole dataset Accuracy score =  96.0\n",
      "myGNB\n",
      "-------------------- myGNB --------------------\n",
      "sklearn Accuracy scores ---------\n",
      "Test Accuracy score =  0.9777777777777777\n",
      "Whole dataset Accuracy score =  0.96\n",
      "My Accuracy scores ---------\n",
      "Test Accuracy score =  97.77777777777777\n",
      "Whole dataset Accuracy score =  96.0\n"
     ]
    }
   ],
   "source": [
    "import sklearn.naive_bayes as sknb\n",
    "models = {\n",
    "    'skGNB': sknb.GaussianNB(),\n",
    "    'myGNB': NaiveBayesClf(algo='gaussian')\n",
    "}\n",
    "models = pipe(X, y, models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.46267984e-12, 2.46267984e-12, 2.46267984e-12, ...,\n",
       "        2.46267984e-12, 2.46267984e-12, 2.46267984e-12],\n",
       "       [2.46267984e-12, 2.46267984e-12, 2.46267984e-12, ...,\n",
       "        2.46267984e-12, 2.46267984e-12, 2.46267984e-12],\n",
       "       [2.46267984e-12, 2.46267984e-12, 2.46267984e-12, ...,\n",
       "        2.46267984e-12, 2.46267984e-12, 2.46267984e-12],\n",
       "       ...,\n",
       "       [2.46267984e-12, 2.46267984e-12, 2.46267984e-12, ...,\n",
       "        2.46267984e-12, 2.46267984e-12, 2.46267984e-12],\n",
       "       [2.46267984e-12, 2.46267984e-12, 2.46267984e-12, ...,\n",
       "        2.46267984e-12, 2.46267984e-12, 2.46267984e-12],\n",
       "       [2.46267984e-12, 2.46267984e-12, 2.46267984e-12, ...,\n",
       "        2.46267984e-12, 2.46267984e-12, 2.46267984e-12]])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models['skGNB'].sigma_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.46267984e-12, 2.46267984e-12, 2.46267984e-12, ...,\n",
       "        2.46267984e-12, 2.46267984e-12, 2.46267984e-12],\n",
       "       [2.46267984e-12, 2.46267984e-12, 2.46267984e-12, ...,\n",
       "        2.46267984e-12, 2.46267984e-12, 2.46267984e-12],\n",
       "       [2.46267984e-12, 2.46267984e-12, 2.46267984e-12, ...,\n",
       "        2.46267984e-12, 2.46267984e-12, 2.46267984e-12],\n",
       "       ...,\n",
       "       [2.46267984e-12, 2.46267984e-12, 2.46267984e-12, ...,\n",
       "        2.46267984e-12, 2.46267984e-12, 2.46267984e-12],\n",
       "       [2.46267984e-12, 2.46267984e-12, 2.46267984e-12, ...,\n",
       "        2.46267984e-12, 2.46267984e-12, 2.46267984e-12],\n",
       "       [2.46267984e-12, 2.46267984e-12, 2.46267984e-12, ...,\n",
       "        2.46267984e-12, 2.46267984e-12, 2.46267984e-12]])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models['myGNB'].sigma2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict\n",
    "<img src=\"https://wikimedia.org/api/rest_v1/media/math/render/svg/1eaed580cf7c29f044a9e517f1cd4a7dd69c4b1f\" style=\"background-color: white\">\n",
    "\n",
    "## Gaussian naive Bayes\n",
    "<img src=\"https://wikimedia.org/api/rest_v1/media/math/render/svg/685339e22f57b18d804f2e0a9c507421da59e2ab\" style=\"background-color: white\">\n",
    "\n",
    "## Multinomial naive Bayes\n",
    "<img src=\"https://wikimedia.org/api/rest_v1/media/math/render/svg/0bf7b8e6edae7359863977eca136558ce5b68568\" style=\"background-color: white\">\n",
    "<pre>Many conditional probabilities are multiplied, one for each feature. This can result in a floating point underflow. It is therefore better to perform the computation by adding logarithms of probabilities instead of multiplying probabilities. The class with the highest log probability score is still the most probable\n",
    "</pre>\n",
    "<img src=\"https://wikimedia.org/api/rest_v1/media/math/render/svg/e53303c0644c3d64e5eb86210023e76198285e0c\" style=\"background-color: white\">\n",
    "\n",
    "## Bernoulli naive Bayes\n",
    "<img src=\"\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
