{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KNN:\n",
    "    def __init__(self, K=5, weights='uniform', distance='minkowski', p=2, epsilon=1e-6):\n",
    "        '''\n",
    "        weights:['uniform', 'distance'] - uniform: All points in each neighborhood are weighted equally.\n",
    "                                          distance: weight points by the inverse of their distance\n",
    "                                                  (closer neighbors of a query point will have a greater influence than neighbors which are further away)\n",
    "        distance:['manhattan','taxicab','euclidean','chebyshev', minkowski','lorentzian','canberra','cosine'] - \n",
    "        https://arxiv.org/pdf/1708.04321.pdf#:~:text=Euclidean%20distance%20is%20the%20most,number%20of%20datasets%2C%20or%20both\n",
    "                  Minkowski = sum(abs(x1-x2)^p+abs(y1-y2)^p)\n",
    "                  Euclidean = Minkowski Distance(p=2)\n",
    "                  Manhattan/Taxicab = Minkowski Distance(p=1)\n",
    "                  Chebyshev = sum(abs(x1-x2)^p,abs(y1-y2)^p)\n",
    "                  Lorentzian = sum(ln(1+abs(x1-x2)))\n",
    "                  Canberra = sum(abs(x1-x2) / (abs(x1)+abs(x2)))\n",
    "                  TODO - Hamming, mahalanobis, braycurtis, etc\n",
    "        epsilon:float - used only when weights='distance'. It is added to the distances only when distance is zero to avoid divide by zero warning\n",
    "        TODO - Implement more efficient storage methods like KD Tree and Ball Tree\n",
    "        '''\n",
    "        assert isinstance(K, int), \"K must be an integer\"\n",
    "        self.K = K\n",
    "        if weights is None or weights.lower() == 'uniform':\n",
    "            self.weights = 'uniform'\n",
    "        elif weights.lower() == 'distance':\n",
    "            self.weights = 'distance'\n",
    "        else:\n",
    "            raise ValueError(\"Unrecognized value for weights, must be 'uniform' or 'distance'\")\n",
    "        distance = distance.lower()\n",
    "        assert distance in ['manhattan', 'taxicab', 'euclidean', 'chebyshev', 'minkowski','lorentzian','canberra','cosine'], \\\n",
    "                f\"Unrecognized distance '{distance}'\"\n",
    "        if distance == 'minkowski':\n",
    "            if isinstance(p, float):\n",
    "                assert np.isinf(p), \"float type for p can be +-numpy.inf only\"\n",
    "            else:\n",
    "                assert isinstance(p, int) and p >= 1, \"p must be an integer and >= 1\"\n",
    "            self.p = p\n",
    "        elif distance == 'euclidean':\n",
    "            distance = 'minkowski'\n",
    "            self.p = 2\n",
    "        elif distance == 'manhattan' or distance == 'taxicab':\n",
    "            distance = 'minkowski'\n",
    "            self.p = 1\n",
    "        elif distance == 'chebyshev':\n",
    "            distance = 'minkowski'\n",
    "            self.p = np.inf\n",
    "        self.distance = distance\n",
    "        self.epsilon = epsilon\n",
    "\n",
    "    def train(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        \n",
    "    def predict_using_for(self, X_test, return_distances=False):\n",
    "        X_train = self.X\n",
    "        n_datapoints, n_features = X_test.shape\n",
    "        assert n_features == X_train.shape[1], \"Training and Prediction data must have same number of features\"\n",
    "        yp = np.full((n_datapoints,), -1)\n",
    "        distances = np.zeros((n_datapoints, self.K, 2))    # 3rd dimension for storing respective classes aong with distances\n",
    "        if self.distance == 'minkowski':\n",
    "            if self.p == np.inf:\n",
    "                if self.weights == 'uniform':\n",
    "                    for i in range(n_datapoints):\n",
    "                        d = np.abs(X_train - X_test[i, :]).max(axis=1)\n",
    "                        ind = np.argsort(d)[:self.K]\n",
    "                        distances[i, :, 0] = d[ind]\n",
    "                        distances[i, :, 1] = self.y[ind]\n",
    "                        # Majority\n",
    "                        top_nn, counts = np.unique(distances[i, :, 1], return_counts=True)\n",
    "                        yp[i] = top_nn[np.argsort(counts)[-1]]\n",
    "                elif self.weights == 'distance':\n",
    "                    for i in range(n_datapoints):\n",
    "                        d = np.abs(X_train - X_test[i, :]).max(axis=1)\n",
    "                        if d.min() == 0.0:\n",
    "                            d = d+self.epsilon\n",
    "                        ind = np.argsort(d)[:self.K]\n",
    "                        distances[i, :, 0] = d[ind]\n",
    "                        distances[i, :, 1] = self.y[ind]\n",
    "                        # Inverse distance Weighted Majority\n",
    "                        w_d = -1\n",
    "                        for c in np.unique(self.y[ind]):\n",
    "                            temp = (1./distances[i, self.y[ind] == c, 0]).sum()\n",
    "                            if temp > w_d:\n",
    "                                w_d = temp\n",
    "                                yp[i] = c\n",
    "            elif self.p == -np.inf:\n",
    "                if self.weights == 'uniform':\n",
    "                    for i in range(n_datapoints):\n",
    "                        d = np.abs(X_train - X_test[i, :]).min(axis=1)\n",
    "                        ind = np.argsort(d)[:self.K]\n",
    "                        distances[i, :, 0] = d[ind]\n",
    "                        distances[i, :, 1] = self.y[ind]\n",
    "                        # Majority\n",
    "                        top_nn, counts = np.unique(distances[i, :, 1], return_counts=True)\n",
    "                        yp[i] = top_nn[np.argsort(counts)[-1]]\n",
    "                elif self.weights == 'distance':\n",
    "                    for i in range(n_datapoints):\n",
    "                        d = np.abs(X_train - X_test[i, :]).min(axis=1)\n",
    "                        if d.min() == 0.0:\n",
    "                            d = d+self.epsilon\n",
    "                        ind = np.argsort(d)[:self.K]\n",
    "                        distances[i, :, 0] = d[ind]\n",
    "                        distances[i, :, 1] = self.y[ind]\n",
    "                        # Inverse distance Weighted Majority\n",
    "                        w_d = -1\n",
    "                        for c in np.unique(self.y[ind]):\n",
    "                            temp = (1./distances[i, self.y[ind] == c, 0]).sum()\n",
    "                            if temp > w_d:\n",
    "                                w_d = temp\n",
    "                                yp[i] = c\n",
    "            else:\n",
    "                if self.weights == 'uniform':\n",
    "                    for i in range(n_datapoints):\n",
    "                        d = np.power((np.abs(X_train - X_test[i, :])**self.p).sum(axis=1), 1./self.p)\n",
    "                        ind = np.argsort(d)[:self.K]\n",
    "                        distances[i, :, 0] = d[ind]\n",
    "                        distances[i, :, 1] = self.y[ind]\n",
    "                        # Majority\n",
    "                        top_nn, counts = np.unique(distances[i, :, 1], return_counts=True)\n",
    "                        yp[i] = top_nn[np.argsort(counts)[-1]]\n",
    "                elif self.weights == 'distance':\n",
    "                    for i in range(n_datapoints):\n",
    "                        d = np.power((np.abs(X_train - X_test[i, :])**self.p).sum(axis=1), 1./self.p)\n",
    "                        if d.min() == 0.0:\n",
    "                            d = d+self.epsilon\n",
    "                        ind = np.argsort(d)[:self.K]\n",
    "                        distances[i, :, 0] = d[ind]\n",
    "                        distances[i, :, 1] = self.y[ind]\n",
    "                        # Inverse distance Weighted Majority\n",
    "                        w_d = -1\n",
    "                        for c in np.unique(self.y[ind]):\n",
    "                            temp = (1./distances[i, self.y[ind] == c, 0]).sum()\n",
    "                            if temp > w_d:\n",
    "                                w_d = temp\n",
    "                                yp[i] = c\n",
    "        elif self.distance == 'canberra':\n",
    "            if self.weights == 'uniform':\n",
    "                for i in range(n_datapoints):\n",
    "                    d = (np.abs(X_train - X_test[i, :]) / (np.abs(X_train) + np.abs(X_test[i, :]))).sum(axis=1)\n",
    "                    ind = np.argsort(d)[:self.K]\n",
    "                    distances[i, :, 0] = d[ind]\n",
    "                    distances[i, :, 1] = self.y[ind]\n",
    "                    # Majority\n",
    "                    top_nn, counts = np.unique(distances[i, :, 1], return_counts=True)\n",
    "                    yp[i] = top_nn[np.argsort(counts)[-1]]\n",
    "            elif self.weights == 'distance':\n",
    "                for i in range(n_datapoints):\n",
    "                    d = (np.abs(X_train - X_test[i, :]) / (np.abs(X_train) + np.abs(X_test[i, :]))).sum(axis=1)\n",
    "                    if d.min() == 0.0:\n",
    "                        d = d+self.epsilon\n",
    "                    ind = np.argsort(d)[:self.K]\n",
    "                    distances[i, :, 0] = d[ind]\n",
    "                    distances[i, :, 1] = self.y[ind]\n",
    "                    # Inverse distance Weighted Majority\n",
    "                    w_d = -1\n",
    "                    for c in np.unique(self.y[ind]):\n",
    "                        temp = (1./distances[i, self.y[ind] == c, 0]).sum()\n",
    "                        if temp > w_d:\n",
    "                            w_d = temp\n",
    "                            yp[i] = c\n",
    "        if return_distances:\n",
    "            return yp, distances\n",
    "        return yp\n",
    "    \n",
    "    def predict(self, X_test, return_distances=False):\n",
    "        '''\n",
    "        top_distances:(K, n_datapoints)\n",
    "        '''\n",
    "        X_train = self.X\n",
    "        n_datapoints, n_features = X_test.shape\n",
    "        assert n_features == X_train.shape[1], \"Training and Prediction data must have same number of features\"\n",
    "        # Broadcast matrices to 3 dimensions for vectorized computation\n",
    "        broadcasted_X1 = np.tile(np.expand_dims(X_train, axis=2), (1,1,n_datapoints))\n",
    "        broadcasted_X2 = np.tile(np.expand_dims(X_test, axis=2).T, (X_train.shape[0],1,1))\n",
    "        # Caclulate feature differences, 1st dimension corresponds to the training points and 3rd dimension corresponds to the test data\n",
    "        diff = np.abs(broadcasted_X1-broadcasted_X2)\n",
    "        # Calculate distance\n",
    "        if self.distance == 'minkowski':\n",
    "            if self.p == np.inf:\n",
    "                all_distances = diff.max(axis=1)\n",
    "            elif self.p == -np.inf:\n",
    "                all_distances = diff.min(axis=1)\n",
    "            else:\n",
    "                all_distances = np.power((diff**self.p).sum(axis=1), 1./self.p)\n",
    "        elif self.distance == 'lorentzian':\n",
    "            all_distances = np.log(1+diff).sum(axis=1)\n",
    "        elif self.distance == 'canberra':\n",
    "            all_distances = (diff / (broadcasted_X1+broadcasted_X2)).sum(axis=1)\n",
    "        elif self.distance == 'cosine':\n",
    "            all_distances = 1 - (broadcasted_X1*broadcasted_X2).sum(axis=1) / \\\n",
    "                            (np.sqrt((broadcasted_X1**2).sum(axis=1)) * np.sqrt((broadcasted_X2**2).sum(axis=1)))\n",
    "        else:\n",
    "            raise NotImplementedError        \n",
    "        # Calculate Prediction\n",
    "        yp = np.full((n_datapoints,), -1)        \n",
    "        indices = np.argsort(all_distances, axis=0)[:self.K]\n",
    "        dummy_i = np.repeat(np.arange(indices.shape[1]).reshape(1, -1), indices.shape[0], axis=0)\n",
    "        top_distances = all_distances[indices, dummy_i]\n",
    "        classes = self.y[indices]\n",
    "        if self.weights == 'uniform':\n",
    "            # Majority\n",
    "            for i in range(n_datapoints):\n",
    "                top_nn, counts = np.unique(classes[:, i], return_counts=True)\n",
    "                yp[i] = top_nn[np.argsort(counts)[-1]]\n",
    "        elif self.weights == 'distance':\n",
    "            top_distances += self.epsilon\n",
    "            # Inverse distance Weighted Majority\n",
    "            for i in range(n_datapoints):\n",
    "                w_d = -1\n",
    "                for c in np.unique(self.y[indices[:,i]]):\n",
    "                    #temp = (1./(all_distances[indices[:,i],i][self.y[indices[:,i]] == c]+self.epsilon)).sum()\n",
    "                    temp = (1./(top_distances[classes[:,i] == c, i])).sum()                    \n",
    "                    if temp > w_d:\n",
    "                        w_d = temp\n",
    "                        yp[i] = c\n",
    "        if return_distances:\n",
    "            return yp, top_distances\n",
    "        return yp\n",
    "\n",
    "    @staticmethod\n",
    "    def score(y, y_pred):\n",
    "        return 100 * (y==y_pred).sum() / len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "X, y = datasets.load_iris(return_X_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.73 ms ± 332 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "m = KNN(weights='distance', p=p)\n",
    "m.train(X, y)\n",
    "myp, d = m.predict_using_for(X, True)\n",
    "accuracy_score(myp, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.68 ms ± 638 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "m = KNN(weights='distance', p=p)\n",
    "m.train(X, y)\n",
    "myp, d = m.predict(X, True)\n",
    "accuracy_score(myp, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, plot_confusion_matrix\n",
    "def pipe(X, y, models, normalize=False, test_size=0.2):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, stratify=y, shuffle=True, random_state=3)\n",
    "    for k in models:\n",
    "        if 'sk' in k:\n",
    "            models[k].fit(X_train, y_train)\n",
    "        else:\n",
    "            if normalize:\n",
    "                X_train = Normalizer(method=norm_method).normalize(X_train)\n",
    "                X_test = Normalizer(method=norm_method).normalize(X_test)\n",
    "            models[k].train(X_train, y_train)\n",
    "\n",
    "        y_pred = models[k].predict(X)\n",
    "        print(\"-\"*20, k, \"-\"*20)\n",
    "        print(\"Test Accuracy score = \", KNN().score(y_test, models[k].predict(X_test)))\n",
    "        print(\"Whole dataset Accuracy score = \", KNN().score(y, y_pred))\n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- skKNN --------------------\n",
      "My Accuracy scores ---------\n",
      "Test Accuracy score =  96.66666666666667\n",
      "Whole dataset Accuracy score =  98.0\n",
      "-------------------- myKNN --------------------\n",
      "My Accuracy scores ---------\n",
      "Test Accuracy score =  96.66666666666667\n",
      "Whole dataset Accuracy score =  98.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "p = 1\n",
    "distance = 'cosine'\n",
    "weights = 'uniform'\n",
    "models = {\n",
    "    'skKNN': KNeighborsClassifier(metric=distance, weights=weights, p=p),\n",
    "    'myKNN': KNN(distance=distance, weights=weights, p=p)\n",
    "}\n",
    "models = pipe(X, y, models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
